<!-- TITLE: Protokolle -->
<!-- SUBTITLE: A quick summary of Protokolle -->

# Protokoll14.05.2019
## interne Prozesse petitcode

- Pro Project eine Seite im Wiki


### Webcrawler

https://wiki.petitcode.com/projects/webcrawler


### Datenbank

- Anforderungen definieren

- Bullhorn ist leider nicht nutzen!


### Nextcloud /Wiki

- Rausfinden ob die Nextcloud plugins integrierbar ist

### TODO

Otti:

- Rollenabbildung im Wiki
- Sixtine fragen wie es rechtlich mit google ist, Daten zu speichern
- Erkundigen wieviel so ne Versicherung kostet - Hiscoix ca 180 Euro (http://finanzchecks.de/)
 

Guy :

- Festhalten der einzelnen Rollen und TÃ¤tigkeiten der Mitarbeiter von petitcode
- Zugang fÃ¼r Sebastian bei bullhorn
- Rausfinden ob die Nextcloud plugins integrierbar ist und welche es Ã¼berhaupt
- Rausfinden welche Alternativen es gibt

Seb :

- Termin festlegen um Wiki Struktur erstellen
- Anforderungen definieren und Ã¼berlegen ob wir selbst programmieren oder ein Tool benutzen

Lukas :

- Herausfinden ob es schon Tools gibt, die Daten aus einem PDF exakt extrahieren und evtl nach Mass persistieren
- Bullhorn anschreiben und eine Lizenz kÃ¼ndigen

Axel :

- Get a quote for D&O coverage (i.e. Directors & Officers insurance for monetary damages to the company caused by an MD)


### Diskussion mit Sixtine 

> [11:51, 21.5.2019] Sixtine: Hey Otti, 
(Sorry Englisch geht schneller in  technische FÃ¤lle ;))
By "Abfrage" do you mean you want to build a crawler or are you accessing the Google maps API directly ? I believe those are two options with different legal requirements
[11:52, 21.5.2019] Sixtine: I have to admit I don't know the legal specifics, rules of thumb I'd say it's probably not really possible.
[11:52, 21.5.2019] Sixtine: Unless you have a licensed access to Google Maps API
[11:53, 21.5.2019] Sixtine: .... For which you probably need to go through the horrible hassle of creating a Google company account etc etc
[11:53, 21.5.2019] Otti: For a Crawler... think you are right
[11:53, 21.5.2019] Sixtine: But it has certain advantages like real time queries etc
[11:54, 21.5.2019] Otti: yes.. thats what i thought and thats what i do in another project.
But i think persisting on profit reason is forbidden.

I only needed your confirmation
[11:55, 21.5.2019] Otti: what about sending a mail with the Data? is this forbidden??? ðŸ¤ª
[11:56, 21.5.2019] Sixtine: Honestly it might not be ..
[11:56, 21.5.2019] Sixtine: But crawlers are always a bit edgy anyways
[11:56, 21.5.2019] Sixtine: I'd say it really depends on the project : if you're paid for doing smth super professional then go to the API
[11:56, 21.5.2019] Otti: thats exactly the Thing!!!
[11:57, 21.5.2019] Sixtine: If youre paid to get shit done, well just do whatever they will never come look for you
[11:57, 21.5.2019] Otti: petticode want a crawler to scan websites, but they even enough research about this ðŸ˜†
[11:57, 21.5.2019] Otti: i think this is really not in interesting of google
[11:57, 21.5.2019] Sixtine: But wait
[11:58, 21.5.2019] Sixtine: This data might be available somewhere else
[11:58, 21.5.2019] Otti: ohhhh... interesting
[11:58, 21.5.2019] Sixtine: I think there exist a platform that lists all the stacks
[11:58, 21.5.2019] Otti: hahaaaaa
[11:58, 21.5.2019] Sixtine: Maybe they have data available
[11:58, 21.5.2019] Sixtine: And then for adresses and stuff I'd actually prefer LinkedIn than Google if you're looking at companies
[11:59, 21.5.2019] Otti: do they have an API?
[12:00, 21.5.2019] Sixtine: LinkedIn probably
[12:00, 21.5.2019] Otti: mmhh... but there is not every flower store in Linked in!
[12:00, 21.5.2019] Sixtine: The other thing I have no idea
[12:00, 21.5.2019] Sixtine: No flower store is probably not the best
[12:00, 21.5.2019] Sixtine: What about Mappy?
[12:00, 21.5.2019] Sixtine: It's a french company that specialises if POI references
